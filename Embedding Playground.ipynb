{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fed2e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d0d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from data_handlers import YCDataset, SampleBatchIdx\n",
    "from utils import compute_normalization_parameters\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "opj = lambda x, y: os.path.join(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c452ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_path = Path('/common/users/dm1487/YouCookII')\n",
    "videos_path = Path('raw_frames/raw_videos')\n",
    "steps_path = Path('raw_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd5c6d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1194, 8), (417, 8))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.read_csv('training_with_labels.csv')\n",
    "validation_df = pd.read_csv('validation_with_labels.csv')\n",
    "training_df.shape, validation_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2af7311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = YCDataset(training_df)\n",
    "batch_sampler = SampleBatchIdx(train_dataset, 8, 24)\n",
    "train_dl = DataLoader(train_dataset, batch_sampler = batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b01109f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonLinearBlock(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, batch_norm):\n",
    "        super(NonLinearBlock, self).__init__()\n",
    "        self.fc = nn.Linear(in_feat, out_feat)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.do_batchnorm = batch_norm\n",
    "        if self.do_batchnorm:\n",
    "            self.norm_func = nn.BatchNorm1d(out_feat)\n",
    "            \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        # TODO: we can switch positions of relu and batch norm to see what happens\n",
    "        if self.do_batchnorm:\n",
    "            x = self.norm_fn(x)\n",
    "        x =  self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba8f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonLinearMapping(nn.Module):\n",
    "    def __init__(self, feat, num_layers, normalization_params=None, batch_norm=False):\n",
    "        super(NonLinearMapping, self).__init__()\n",
    "        self.nonlin_mapping = nn.Sequential(*[NonLinearBlock(feat, feat, batch_norm) for _ in range(num_layers - 1)])\n",
    "        \n",
    "        if num_layers > 0:\n",
    "            self.lin_mapping = nn.Linear(feat, feat)\n",
    "        else:\n",
    "            self.lin_mapping = lambda x : torch.zeros_like(x) ## for no layers, do not do anything\n",
    "        \n",
    "        self.register_buffer('norm_mean', torch.zeros(feat))\n",
    "        self.register_buffer('norm_sigma', torch.ones(feat))\n",
    "    \n",
    "    def initialize_normalization(self, normalization_params):\n",
    "        if normalization_params is not None:\n",
    "            if len(normalization_params) > 0:\n",
    "                self.norm_mean.data.copy_(normalization_params[0])\n",
    "            if len(normalization_params) > 1:\n",
    "                self.norm_mean.data.copy_(normalization_params[1])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = (x - self.norm_mean)/ self.norm_sigma\n",
    "        res = self.nonlin_mapping(x)\n",
    "        # TODO: maybe add a dropout here\n",
    "        res = self.lin_mapping(res)\n",
    "        return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32952d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsMapping(nn.Module):\n",
    "    def __init__(self, feat, video_layers=2, text_layers=2, drop_layers=1, learnable_drop=False, normalization_dataset=None, batch_norm=False):\n",
    "        super(EmbeddingsMapping, self).__init__()\n",
    "        self.video_mapping = NonLinearMapping(feat, video_layers, batch_norm)\n",
    "        self.text_mapping = NonLinearMapping(feat, text_layers, batch_norm)\n",
    "        \n",
    "        if learnable_drop:\n",
    "            self.drop_mapping = NonLinearMapping(feat, drop_layers, batch_norm)\n",
    "        \n",
    "        if normalization_dataset is not None:\n",
    "            norm_params = compute_normalization_parameters(normalization_dataset, feat)\n",
    "            self.video_mapping.initialize_normalization(norm_params[:2])\n",
    "            self.text_mapping.initialize_normalization(norm_params[2:])\n",
    "            \n",
    "    def map_video(self, x):\n",
    "        return self.video_mapping(x)\n",
    "\n",
    "    def map_text(self, z):\n",
    "        return self.text_mapping(z)\n",
    "    \n",
    "    def compute_distractors(self, v):\n",
    "        return self.drop_mapping(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6077b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmbeddingsMapping(512, video_layers=2, text_layers=2, drop_layers=2, learnable_drop=True, normalization_dataset=train_dataset)\n",
    "model = model.to('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aec3c721",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = next(iter(train_dl))\n",
    "distractor = torch.stack([s.mean(0) for s in dp['step_feature']], 0).to('cuda:1')\n",
    "vf, sf = dp['video_feature'].to('cuda:1'), dp['step_feature'].to('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97b8a129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24, 500, 512]), torch.Size([24, 16, 512]), torch.Size([24, 512]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.map_video(vf).shape, model.map_text(sf).shape, model.compute_distractors(distractor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40de5109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
