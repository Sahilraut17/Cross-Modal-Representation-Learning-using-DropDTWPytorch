# Cross-Modal-Representation-Learning-using-DropDTWPytorch

Final Project for Course 536 Machine Learing Rutgers University

Cross Modal Representation Learning has been one of the most relevant topics in the context of the world today. We generate massive amounts of data every second, be it video-audio-text from Youtube videos, tags or captions accompanying images from social media websites like Instagram, Twitter. Understanding such data brings value in tasks like image retrieval, video segment retrieval, step localization, captioning images, etc. Being able to understand one modality from the other brings us one step closer to intelligence like we haven't seen before.
In this project wea are learning video-text representations and doing so using a proxy task of alignment using Drop-Dynamic Time Warping (Drop-DTW) on an instructional video dataset YouCookII. 
