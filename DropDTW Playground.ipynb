{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "009e1765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c029137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from data_handlers import YCDataset, SampleBatchIdx\n",
    "from models import EmbeddingsMapping\n",
    "from losses import compute_clust_loss, compute_alignment_loss\n",
    "from utils import compute_normalization_parameters\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, log, exp\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "opj = lambda x, y: os.path.join(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0590bfb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1194, 8), (417, 8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.read_csv('training_with_labels.csv')\n",
    "validation_df = pd.read_csv('validation_with_labels.csv')\n",
    "training_df.shape, validation_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b372203",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = YCDataset(training_df)\n",
    "batch_sampler = SampleBatchIdx(train_dataset, 8, 24)\n",
    "train_dl = DataLoader(train_dataset, batch_sampler = batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088d24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:2'\n",
    "model = EmbeddingsMapping(512, video_layers=2, text_layers=2, drop_layers=2, learnable_drop=True, normalization_dataset=train_dataset)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b1f8c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "tensor(3.9998, device='cuda:2', grad_fn=<MeanBackward0>) tensor(9.0510, device='cuda:2', grad_fn=<AddBackward0>)\n",
      "5\n",
      "tensor(3.9998, device='cuda:2', grad_fn=<MeanBackward0>) tensor(9.0510, device='cuda:2', grad_fn=<AddBackward0>)\n",
      "5\n",
      "tensor(3.9998, device='cuda:2', grad_fn=<MeanBackward0>) tensor(9.0510, device='cuda:2', grad_fn=<AddBackward0>)\n",
      "5\n",
      "tensor(3.9998, device='cuda:2', grad_fn=<MeanBackward0>) tensor(9.0510, device='cuda:2', grad_fn=<AddBackward0>)\n",
      "5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2603534/1882565081.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mclust_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_clust_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdif\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mzx_costs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_costs_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_alignment_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdif\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_normalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_xz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_percentile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdtw_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_dropDTW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzx_costs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_costs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclust_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtw_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2603534/180804269.py\u001b[0m in \u001b[0;36mbatch_dropDTW\u001b[0;34m(zx_costs_list, drop_costs_list, exclusive, contiguous)\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mpos_neighbours\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdp_up\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mDp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_neighbours\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mall_zx_costs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz_cost_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cost_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mDm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_left\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mall_drop_costs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_cost_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2603534/1103213848.py\u001b[0m in \u001b[0;36mminProb\u001b[0;34m(inputs, gamma, keepdim)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mminP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mminP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1677\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1679\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1680\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_model(vf, sf, distractor):\n",
    "    frame_features = model.map_video(vf)\n",
    "    step_features = model.map_text(sf)\n",
    "    distractor_features = model.compute_distractors(distractor)\n",
    "\n",
    "    return frame_features, step_features, distractor_features\n",
    "\n",
    "frame_gamma = 10\n",
    "gamma_xz = 10\n",
    "keep_percentile = 1\n",
    "l2_normalize = False\n",
    "for batch in train_dl:\n",
    "    step_len, step_features, video_len, video_features = batch['step_len'], batch['step_feature'], batch['video_len'], batch['video_feature']\n",
    "    distractors = torch.stack([ s[:size].mean(0) for s, size in zip(step_features, step_len)], dim=0) # also taking care of the distractor padding (dont worry about it later)\n",
    "    ff, sf, dif = run_model(video_features.to(device), step_features.to(device), distractors.to(device))\n",
    "    clust_loss = compute_clust_loss((sf, step_len, ff, video_len, dif), device=device)\n",
    "    zx_costs_list, drop_costs_list = compute_alignment_loss((sf, step_len, ff, video_len, dif), l2_normalize, gamma_xz, keep_percentile)\n",
    "    dtw_loss, D = batch_dropDTW(zx_costs_list, drop_costs_list)\n",
    "    print(clust_loss, sum([c/len(batch) for c in dtw_loss]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45aff590",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VarTable():\n",
    "    def __init__(self, dims, device):\n",
    "        self.dims = dims\n",
    "        d1, d2, d_rest = dims[0], dims[1], dims[2:]\n",
    "        \n",
    "        self.vars = []\n",
    "        \n",
    "        # creating the dtw table\n",
    "        for i in range(d1):\n",
    "            self.vars.append([])\n",
    "            for j in range(d2):\n",
    "                var = torch.zeros(d_rest).to(torch.float).to(device)\n",
    "                self.vars[i].append(var)\n",
    "    \n",
    "    def __getitem__(self, pos):\n",
    "        i, j = pos\n",
    "        return self.vars[i][j]\n",
    "\n",
    "    def __setitem__(self, pos, new_val):\n",
    "        i, j = pos\n",
    "        if self.vars[i][j].sum() != 0:\n",
    "            assert False, 'already assigned'\n",
    "        else:\n",
    "            self.vars[i][j] = self.vars[i][j] + new_val\n",
    "            \n",
    "    def show(self):\n",
    "        pass # TODO: needs to be added for visualization\n",
    "    \n",
    "def minProb(inputs, gamma = 1, keepdim = True):\n",
    "    if inputs[0].shape[0] == 1:\n",
    "        inputs = torch.cat(inputs)\n",
    "    else:\n",
    "        inputs = torch.stack(inputs, dim = 0)\n",
    "    probs = F.softmax(- inputs / gamma, dim = 0)\n",
    "    minP = (probs * inputs).sum(dim = 0, keepdim = keepdim)\n",
    "    return minP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7c9250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_dropDTW(zx_costs_list, drop_costs_list, exclusive=True, contiguous=True):\n",
    "    \n",
    "    inf = 99999999\n",
    "    min_fn = minProb\n",
    "    \n",
    "    # to find max padding need to run drop-dtw in batches \n",
    "    B = len(zx_costs_list)\n",
    "    Ns, Ks = [], []\n",
    "    \n",
    "    for i in range(B):\n",
    "        Ki, Ni = zx_costs_list[i].shape\n",
    "        Ns.append(Ni)\n",
    "        Ks.append(Ki)\n",
    "    \n",
    "    N, K = max(Ns), max(Ks)\n",
    "    \n",
    "    \n",
    "    padded_cum_drop_costs, padded_drop_costs, padded_zx_costs = [], [], []\n",
    "    \n",
    "    for i in range(B):\n",
    "        zx_costs = zx_costs_list[i]\n",
    "        drop_costs = drop_costs_list[i]\n",
    "        cum_drop_costs = torch.cumsum(drop_costs, dim=0)\n",
    "        \n",
    "        row_pad = torch.zeros([N - Ns[i]]).to(zx_costs.device)\n",
    "#         print(row_pad.shape)\n",
    "#         print(cum_drop_costs.shape)\n",
    "#         print(torch.cat([cum_drop_costs, row_pad]).shape)\n",
    "        padded_cum_drop_costs.append(torch.cat([cum_drop_costs, row_pad]))\n",
    "#         print(len(padded_cum_drop_costs))\n",
    "        padded_drop_costs.append(torch.cat([drop_costs, row_pad]))\n",
    "        \n",
    "        multirow_pad = torch.stack([row_pad + inf] * Ks[i], dim=0) # to add padding to each row\n",
    "#         print(multirow_pad.shape)\n",
    "        \n",
    "#         print('padded_table', zx_costs.shape)\n",
    "\n",
    "        padded_table = torch.cat([zx_costs, multirow_pad], dim=1)\n",
    "#         print('padded_table', padded_table.shape)\n",
    "        \n",
    "        rest_pad = torch.zeros([K - Ks[i], N]).to(zx_costs.device) + inf\n",
    "        padded_table = torch.cat([padded_table, rest_pad], dim=0)\n",
    "        \n",
    "#         print(padded_table.shape)\n",
    "        \n",
    "        padded_zx_costs.append(padded_table)\n",
    "        \n",
    "#         print(\"####\")\n",
    "    \n",
    "    all_zx_costs = torch.stack(padded_zx_costs, dim=-1)\n",
    "    all_cum_drop_costs = torch.stack(padded_cum_drop_costs, dim=-1)\n",
    "    all_drop_costs = torch.stack(padded_drop_costs, dim=-1)\n",
    "    \n",
    "    \n",
    "    D = VarTable((K + 1, N + 1, 3, B), device)\n",
    "    for zi in range(1, K + 1): \n",
    "        D[zi, 0] = torch.zeros_like(D[zi, 0]) + inf # init all rows '0th' row with inf \n",
    "    for xi in range(1, N + 1):\n",
    "        D[0, xi] = torch.zeros_like(D[0, xi]) + all_cum_drop_costs[(xi - 1):xi] # init all columns '0th' col with cumulative drops\n",
    "        \n",
    "        \n",
    "    for zi in range(1, K+1):\n",
    "        for xi in range(1, N+1):\n",
    "            z_cost_ind, x_cost_ind = zi-1, xi-1\n",
    "            \n",
    "            d_diag, d_left = D[zi-1, xi-1][0:1], D[zi-1, xi][0:1]\n",
    "            dp_left, dp_up = D[zi, xi-1][2:3], D[zi-1, xi][2:3]\n",
    "            \n",
    "            if contiguous:\n",
    "                pos_neighbours = [d_diag, dp_left]\n",
    "            else:\n",
    "                pos_neighbours = [d_diag, d_left]\n",
    "                \n",
    "            if not exclusive:\n",
    "                pos_neighbours.append(dp_up)\n",
    "\n",
    "            Dp = min_fn(pos_neighbours) + all_zx_costs[z_cost_ind, x_cost_ind]\n",
    "            \n",
    "            Dm = d_left + all_drop_costs[x_cost_ind]\n",
    "            \n",
    "            D_final = min_fn([Dm, Dp])\n",
    "            \n",
    "            D[zi, xi] = torch.cat([D_final, Dm, Dp], dim=0)\n",
    "    \n",
    "    min_costs = []\n",
    "    for i in range(B):\n",
    "        Ni, Ki = Ns[i], Ks[i]\n",
    "        min_cost_i = D[Ki, Ni][0, i]\n",
    "        min_costs.append(min_cost_i / Ni)\n",
    "        \n",
    "    return min_costs, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97641e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a2c457",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
